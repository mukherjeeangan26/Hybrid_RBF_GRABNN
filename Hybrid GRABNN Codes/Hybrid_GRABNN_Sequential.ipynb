{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de97b54d-a104-4481-8276-70f9d65f962f",
   "metadata": {},
   "source": [
    "**Sequential Training of Unconstrained Hybrid Gaussian RAdial Basis Neural Networks (GRAB-NN) Models**\n",
    "\n",
    "This code demonstrates the sequential training algorithms developed for hybrid GRAB-NN models by exploting the model architecture and using different training / optimization algorithms for solving all submodels, while still solving an outer layer optimization to ensure overall convergence. The hidden layer consists of two different types of nodes -- namely, the ANN nodes with sigmoid activation function and the RBF nodes with Gaussian activation function. The centers and widths of RBF nodes in hidden layer are optimized by IPOPT. The hidden layer weights for the ANN are estimated by typical backpropagation based first-order approaches. The output layer weights for the overall GRAB-NN model are estimated by Orthogonal Least Squares (OLS) algorithm. The sequence of ANN and RBF nodes in the hidden layer is immaterial since the network architecture represents a fully-connected NN model.\n",
    "\n",
    "The model structure can be optimized simultaneously / sequentially by the MINLP approaches proposed in this work. However, this code simply compares the predictive performances of different combinations of model architectures by comprehensive enumeration for a fixed size / structure of the network, i.e., for a fixed total number of hidden layer nodes in the overall GRAB-NN model.\n",
    "\n",
    "The model parameters are initialized by cubic spline interpolation during implementation (not included in this code). This code, however, provides a simple demonstration of how the sequential training is performed for the hybrid GRAB-NN models. Furthermore, with same initialization both simultaneous and sequential approaches led to the same solution practically, but the latter was significantly computationally faster than the former.\n",
    "\n",
    "*Load the training and validation datasets and specify the input and output variables for the RBF models. Note that the user can consider any dynamic dataset for training and validation. The rows signify the time steps for transient data and the columns signify the input and output variables.*\n",
    "\n",
    "*The nonlinear dynamic continuous stirred tank reactor (CSTR) system is chosen for demonstration of the proposed approach.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c3858f-d0f0-4c9e-94f6-5e4d8f3603b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pyomo.environ as pyo\n",
    "from pyomo.opt import SolverFactory\n",
    "from idaes.core.solvers import get_solver\n",
    "get_solver()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pyDOE import *\n",
    "import math as mt\n",
    "import time\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bceebfa5-516d-4fc0-b22c-4cfbd1fe5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data for model development\n",
    "\n",
    "data = pd.read_excel(\"Dynamic CSTR Data.xlsx\",\"Data\", header=None).values\n",
    "data = data[2:1202, 1:]\n",
    "\n",
    "# For this specific system, the first five columns are the model inputs and the following four columns are the model outputs\n",
    "\n",
    "input_data = data[:,0:5]\n",
    "output_data = data[:,5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b60df-14de-4bef-b81d-8a4b3af65204",
   "metadata": {},
   "source": [
    "**Defining three individual optimization (sub)problems**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3a8d0-5876-4a77-b609-c4358c1f2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBF_hidden(tn,ni,Imat_t,dsr_RBF_t,nh_RBF):\n",
    "\n",
    "    nh = nh_RBF\n",
    "\n",
    "    # Setting up the optimization problem\n",
    "\n",
    "    M = pyo.ConcreteModel()\n",
    "\n",
    "    M.I1 = pyo.RangeSet(1, ni)\n",
    "    M.I2 = pyo.RangeSet(1, nh)\n",
    "    M.I3 = pyo.RangeSet(1, 1)\n",
    "    M.I4 = pyo.RangeSet(1,tn)\n",
    "    \n",
    "    M.x1 = pyo.Var(M.I1,M.I2, bounds = (1e-3,2.5), initialize = 0.5)  # centermat (RBF)\n",
    "    M.x2 = pyo.Var(M.I3, bounds = (1e-3,4), initialize = 1)           # sigma (RBF)\n",
    "\n",
    "    M.y1 = pyo.Var(M.I2,M.I4)                     # PhiofD / y_h (RBF)\n",
    "    \n",
    "    @M.Expression(M.I2, M.I4)\n",
    "    def D(M,i,j):\n",
    "        return (sum((Imat_t[k-1,j-1] - M.x1[k,i])**2 for k in M.I1))**0.5   \n",
    "    \n",
    "    def constraint_rule_1(M,i,j):\n",
    "        return M.y1[i,j] == (1/pyo.sqrt(2*mt.pi*M.x2[1]**2))*pyo.exp(-(M.D[i,j] * M.D[i,j])/(2*M.x2[1]**2)) \n",
    "    \n",
    "    M.constraint_1 = pyo.Constraint(M.I2, M.I4, rule = constraint_rule_1)\n",
    "           \n",
    "    def GRBF_optim_det(M):             \n",
    "        obj_value = sum(sum((dsr_RBF_t[i-1,j-1] - M.y1[i,j]) ** 2 for i in M.I2) for j in M.I4)\n",
    "        return obj_value\n",
    "    \n",
    "    M.obj = pyo.Objective(rule = GRBF_optim_det, sense = pyo.minimize)\n",
    "    \n",
    "    solver = pyo.SolverFactory('ipopt')\n",
    "    solver.options['max_iter'] = 350\n",
    "    \n",
    "    results = solver.solve(M, tee = True)\n",
    "    \n",
    "    yRBF = np.zeros((nh,tn))\n",
    "    for (i,j) in M.y1:\n",
    "        yRBF[i-1,j-1] = pyo.value(M.y1[i,j])\n",
    "    \n",
    "    return yRBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cabe25-5441-4bfe-b1a2-fd5550a9d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_BP_hidden(tn,ni,Imat_t,dsr_ANN_t,nh_ANN):\n",
    "\n",
    "    nh = nh_ANN\n",
    "    wh = np.random.rand(ni,nh)\n",
    "    max_iter = 10000\n",
    "    eta = 0.01\n",
    "    tol = 1e-4\n",
    "\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        yANN = 1/(1+np.exp(-np.dot(wh.T,Imat_t)))\n",
    "        err = dsr_ANN_t - yANN\n",
    "        mse = np.mean(err**2)\n",
    "\n",
    "        if (mse>=tol):\n",
    "            delta_y = yANN*(np.ones_like(yANN) - yANN)*err\n",
    "            wh = wh.T + eta*np.dot(delta_y,Imat_t.T)\n",
    "            wh = wh.T\n",
    "\n",
    "    return yANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41933c-9583-4d96-ad47-2b5ee002d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBFANN_output_OLS(y_h,dsr_t):\n",
    "\n",
    "    wo = np.dot(np.transpose(np.linalg.pinv(y_h)) , dsr_t.T)\n",
    "\n",
    "    yRBFANN = np.dot(y_h.T,wo)\n",
    "\n",
    "    return yRBFANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eec1d8-e989-440e-9ada-606460ad50dc",
   "metadata": {},
   "source": [
    "**Defining the Outer Optimization Problem for Overall Convergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1976ec3-f95b-44e7-9d55-76b92fb3f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_optim_RBFANN(tn,ni,nh_RBF,nh_ANN,Imat_t,dsr_t):\n",
    "\n",
    "    tol = 1e-2\n",
    "    flag = 1\n",
    "    \n",
    "    nh = nh_RBF + nh_ANN\n",
    "\n",
    "    error_h = 1e2\n",
    "\n",
    "    # Initializing intermediate inputs y_h\n",
    "    w0 = np.random.rand(ni,nh)\n",
    "    y_h = np.dot(w0.T,Imat_t)\n",
    "\n",
    "    while(error_h > tol and flag < 3):        \n",
    "    \n",
    "        y_RBFANN = RBFANN_output_OLS(y_h,dsr_t)\n",
    "    \n",
    "        dsr_RBF_t = y_h[:nh_RBF]\n",
    "        dsr_ANN_t = y_h[nh_RBF:]\n",
    "    \n",
    "        if not (nh_RBF == 0):\n",
    "            yRBF_h = RBF_hidden(tn,ni,Imat_t,dsr_RBF_t,nh_RBF)\n",
    "\n",
    "        if not (nh_ANN == 0):\n",
    "            yANN_h = NN_BP_hidden(tn,ni,Imat_t,dsr_ANN_t,nh_ANN)\n",
    "    \n",
    "        if (nh_RBF == 0):\n",
    "            yRBFANN_h = yANN_h\n",
    "        elif (nh_ANN == 0):\n",
    "            yRBFANN_h = yRBF_h\n",
    "        else:\n",
    "            yRBFANN_h = np.vstack((yRBF_h,yANN_h))\n",
    "    \n",
    "        error_h = np.linalg.norm((y_h - yRBFANN_h)**2)\n",
    "        \n",
    "        y_h = yRBFANN_h\n",
    "        flag += 1\n",
    "        \n",
    "\n",
    "    return y_RBFANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b7976d-5cc3-4faa-bdab-b05de309edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specification of Model Inputs and Target Outputs\n",
    "\n",
    "data = np.concatenate((input_data, output_data), axis = 1)\n",
    "ni = input_data.shape[1]\n",
    "no = output_data.shape[1]\n",
    "nt = ni+no\n",
    "\n",
    "tt = data.shape[0]\n",
    "tn = int(np.floor(1*tt))\n",
    "\n",
    "# Normalizing the input and output variables\n",
    "\n",
    "norm_mat = np.zeros((tt,nt))\n",
    "delta = np.zeros((1,nt))\n",
    "for i in range(nt):\n",
    "    delta[:,i] = max(data[:,i]) - min(data[:,i])\n",
    "    norm_mat[:,i] = (data[:,i] - min(data[:,i]))/delta[0,i]\n",
    "\n",
    "Imat = norm_mat[:,0:ni].T\n",
    "dsr = norm_mat[:,ni:ni+no].T\n",
    "\n",
    "# TRAINING OF RBFNN\n",
    "\n",
    "tr_steps = np.random.choice(tt, tn, replace=False)\n",
    "tr_steps = np.sort(tr_steps) \n",
    "\n",
    "dsr_t = np.zeros((no,tn))\n",
    "Imat_t = np.zeros((ni,tn))\n",
    "\n",
    "for i in range(tn):\n",
    "    ts = tr_steps[i]\n",
    "    dsr_t[:,i] = dsr[:,ts]\n",
    "    Imat_t[:,i] = Imat[:,ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c89b9c-125b-4d75-a2dd-1e651a5e3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Enumeration of all possible combinations of RBF and ANN nodes in the Hidden Layer\n",
    "\n",
    "# Specify the size of the hidden layer (i.e., number of nodes)\n",
    "nh = 15\n",
    "\n",
    "check = 1e6\n",
    "\n",
    "k_v = []; mse_v = [];\n",
    "\n",
    "target_unnorm = np.zeros((tn,no))\n",
    "for i in range(no):\n",
    "    target_unnorm[:,i] = np.transpose(dsr_t[i])*delta[0,ni+i] + min(data[:,ni+i])\n",
    "\n",
    "for i in range(nh+1):\n",
    "    nh_ANN = i\n",
    "    nh_RBF = nh - nh_ANN\n",
    "\n",
    "    if (nh_RBF == 0):\n",
    "        yANN = outer_optim_RBFANN(tn,ni,nh_RBF,nh_ANN,Imat_t,dsr_t)\n",
    "        yANN_unnorm = np.zeros((tn,no))\n",
    "        for i in range(no):\n",
    "            yANN_unnorm[:,i] = yANN[:,i]*delta[0,ni+i] + min(data[:,ni+i])\n",
    "        mse = np.mean((np.divide((target_unnorm - yANN_unnorm),target_unnorm))**2)\n",
    "        k = ni*nh + nh*no\n",
    "    elif (nh_ANN == 0):\n",
    "        yRBF = outer_optim_RBFANN(tn,ni,nh_RBF,nh_ANN,Imat_t,dsr_t)\n",
    "        yRBF1_unnorm = np.zeros((tn,no))\n",
    "        for i in range(no):\n",
    "            yRBF1_unnorm[:,i] = yRBF[:,i]*delta[0,ni+i] + min(data[:,ni+i])\n",
    "        mse = np.mean((np.divide((target_unnorm - yRBF1_unnorm),target_unnorm))**2)\n",
    "        k = ni*nh + 1 + nh*no\n",
    "    else:\n",
    "        yRBFANN = outer_optim_RBFANN(tn,ni,nh_RBF,nh_ANN,Imat_t,dsr_t)\n",
    "        yRBFANN_unnorm = np.zeros((tn,no))\n",
    "        for i in range(no):\n",
    "            yRBFANN_unnorm[:,i] = yRBFANN[:,i]*delta[0,ni+i] + min(data[:,ni+i])\n",
    "        mse = np.mean((np.divide((target_unnorm - yRBFANN_unnorm),target_unnorm))**2)\n",
    "        k = ni*nh + 1 + nh*no\n",
    "\n",
    "    k_v.append(k)\n",
    "    mse_v.append(mse)\n",
    "\n",
    "    # Note that in this code, in absence of cubic spline interpolation the monotonicity of MSE values may not be guaranteed. Random initialization may\n",
    "    # lead to local optima. The number of parameters in all different combinations have been kept the same / similar to ensure fair comparison\n",
    "\n",
    "    if (mse_v[-1] < check and nh_RBF > 0 and nh_ANN > 0):\n",
    "        check = mse_v[-1]\n",
    "        yopt = yRBFANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab18bb-83b8-4a26-8b01-24d29d518c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the optimal model architecture, i.e., optimal values of nh_ANN and nh_RBF\n",
    "\n",
    "nh_ANN_opt = np.argmin(mse_v)\n",
    "nh_RBF_opt = nh - nh_ANN_opt\n",
    "\n",
    "print('Optimal GRABNN architecture ==> nh_ANN:', nh_ANN_opt, 'and nh_RBF:', nh_RBF_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2acd999-851f-497f-a8cc-be365246c33a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
